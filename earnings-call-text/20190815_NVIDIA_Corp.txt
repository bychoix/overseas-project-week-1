Q2 2020 Earnings Call

Presentation
Operator
Good afternoon, my name is Christina and I will be your conference operator today. Welcome to
NVIDIA's Financial Results Conference Call. (Operator Instructions) Thank you. I will now turn the
call over to `Simona Jankowski, Investor Relations from Investor Relations to begin your conference.
`Simona Jankowski, Investor Relations `
Thank you. Good afternoon, everyone and welcome to NVIDIA's conference call for the second
quarter of fiscal 2020. With me on the call today from NVIDIA are `Jensen Huang, President and Chief Executive Officer, President and
Chief Executive Officer; and `Colette Kress, Executive Vice President and Chief Financial Officer, Executive Vice President and Chief Financial Officer.
I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website.
The webcast will be available for replay until the conference call to discuss our financial results for
the third quarter of fiscal 2020. The content of today's call is NVIDIA's property. It can't be
reproduced or transcribed without our prior written consent.
During this call, we may make forward-looking statements based on current expectations. These
are subject to a number of significant risks and uncertainties, and our actual results may differ
materially. For a discussion of factors that could affect our future financial results and business,
please refer to the disclosure in today's earnings release, our most recent Forms 10-K and 10-Q
and the reports that we may file on Form 8-K with the Securities and Exchange Commission.
All our statements are made as of today, August 15, 2019, based on information currently
available to us except as required by law, we assume no obligation to update any such
statements. During this call, we will discuss non-GAAP financial measures. You can find a
reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO
commentary, which is posted on our website.
With that, let me turn the call over to Colette.
`Colette Kress, Executive Vice President and Chief Financial Officer `Thanks, Simona. Q2 revenue was $2.58 billion in line with our outlook, down 17% year-on-year and
up 16% sequentially. Starting with our gaming business, revenue of $1.31 billion was down 27%
year-on-year and up 24% sequentially. We are pleased with the strong sequential growth in the
quarter, when we launched our RTX Super lineup for desktop gamers, ramped up our greatest
ever number of gaming laptops and launched our new RTX Studio laptops for creators.
In July, we unveiled three GeForce RTX Super GPUs delivering the best-in-class gaming
performance and power efficiency and real-time ray tracing for both current and next generation
games. These GPUs deliver a performance boost of up to 24% from our initial Turing GPUs
launched a year earlier. The Super lineup strengthens our leadership in the high end of the
market and the response has been great. We look forward to delighting gamers with the best
performance in ray tracing as we get into the back-to-school and holiday shopping seasons.
Ray tracing is taking the gaming industry by storm and have quickly come to define the modern
era of computer graphics, a growing number of blockbuster AAA titles have announced support
for NVIDIA RTX ray tracing including Call of Duty: Modern Warfare, Cyberpunk 2077, Watch Dogs:
Legion, and Wolfenstein: Youngblood. Excitement around these titles is tremendous. GameSpot
called Cyberpunk one of the most anticipated games of the decade
NVIDIA GeForce RTX are the only graphic cards in the market with hardware support for ray
tracing. They deliver a 2x to 3x performance speed up over GPUs without a dedicated ray tracing
core. The laptop business continues to be a standout growth driver as OEMs are ramping a
record 100 plus gaming laptop models, ahead of the back-to-school and holiday season.
The combination of our energy efficient Turing architecture and Max-Q technology enables
beautifully crafted thin and light form factors that can deliver the performance of a high-end
gaming desktop or a next generation console. At Computex in May, we unveiled NVIDIA RTX
Studio laptops, a new design artist platform that extends our reach to the large underserved
market of creators. In the age of YouTube, creators and freelancers are rapidly growing
population but they have traditionally not had access to professional grade workstations through
online and retail channels.
RTX Studio laptops are designed to meet their increasing complex workflows such as photo-
realistic ray tracing, AI image enhancement and ultra high resolution video. Powered by our RTX
GPUs and optimized software, RTX Studio laptops deliver performance that's up to 7 times faster
than that of the MacBook Pro. A total of 27 RTX Studio models have been announced by major
OEMs. Sequential growth also benefited from the production ramp of the two new models of
Nintendo Switch gaming console. We expected our console business to remain strong in Q3
before the seasonal production slow down in Q4, when console related revenue is expected to
be fairly minimal, similar to last year.
Moving to data center, revenue was $655 million, down 14% year-on-year and up 3% sequentially.
In the vertical industries portion of the business, expanding AI workloads drove sequential and
year-over-year growth. In hyperscale portion, we continue to be impacted by relatively weak
overall spending as a handful of CSPs. Sales of NVIDIA GPUs for use in the cloud were solid, while
sales for internal hyperscales use were muted, the engineering focus on AI is growing.
Let me give some color on each of these areas. We are building a broad base of customers
across multiple industries as they adopt NVIDIA's platforms to harness the power of AI, public
sectors, higher education and financial services were among the key verticals driving growth this
quarter. In addition, we won Lighthouse account deals in important industries that are on the cusp
of being transformed by AI. For example, in retail, Walmart is using NVIDIA GPUs to run some ofits product demand forecasting models slashing the time to do so in just four hours from several
weeks on CPUs. By accelerating its data science workflow, Walmart can improve its algorithms,
reduce development cycles and test new features.
Earlier this week, we announced breakthroughs for the fastest training and inference of the state
of the art model for natural language process understanding called BERT or bidirectional encoder
representations of -- from transformers. A breakthrough, AI language model that achieves a
deeper sense of language context and meaning. This can enable near human comprehension in
real time by Chatbox intelligent personal assistance and search engines.
We are working with Microsoft as an early adopter of these advances. AI computing leadership is
a high priority for NVIDIA. Last month, we set records for training deep learning neural network
models on the latest MLPerf benchmarks, particularly in the most demanding areas. In just seven
months, we have achieved up to 80% seed-ups enabled by new algorithms and software
optimizations across the full stock while using the same hardware.
This is a direct result of the product -- productive programming environment, and flexibility of
CUDA. Delivering AI at scale isn't just about silicon, it's about optimizing across the entire high
performance computing system. In fact, the NVIDIA AI platform is getting progressively faster.
Every month, we published new optimization and performance improvement to CUDA-X AI
libraries supporting every AI framework and development environment .
All in, our ecosystem of developers is now 1.4 million strong. In setting these MLPerf records, we
leveraged our new DGX SuperPOD AI supercomputer, demonstrating that leadership in AI
research demands leadership in computing infrastructure. This system debuted in June at
Number 22 on the top 500 list of the world's fastest supercomputers at the Annual International
Supercomputing Conference, used to meet the massive demand of our autonomous vehicle
development program. It is powered by more than 1500 NVIDIA V100 Tensor Core GPUs linked
with Mellanox interconnects. We've made DGX SuperPOD available commercially to customers.
Essentially, providing them with a turnkey supercomputer that they can assemble in weeks rather
than months. It is roughly 400 times smaller in size than other similarly performing top 500
systems, which are built from thousands of servers. Also at the conference, we announced that
by next year's end, we will make available to the Arm ecosystem, NVIDIA's full stack of AI and
HPC software which accelerates more than 600 HPC applications and all AI frameworks. With this
announcement, NVIDIA will accelerate all major CPU architectures including x86, POWER and Arm.
Lastly, regarding our pending acquisition of Mellanox, we have received regulatory approval in the
US and are engaged with regulators in Europe and China. The approval process is progressing as
expected and we continue to work toward closing the deal by the end of this calendar year.
Moving to pro visualization. Revenue reached $291 million, up 4% from a prior year and up 9%
sequentially. Year-on-year and sequential growth was led by record revenue from mobile
workstations with strong demand for new thin and light form factors. We had a great showing at
SIGGRAPH, the computer graphics industry's biggest annual conference held in Los Angeles. Our
researchers won several best in show rewards in just a year since the launch of RTX ray tracing
over 40 design and creative applications with RTX technology have been announced by leading
software vendors, including Adobe, Autodesk and Dassault Systemes and many others.
NVIDIA RTX technologies has reinvigorated the computer graphics industry by enabling
researchers and developers to take a leap in photorealistic rendering, augmented reality and
virtual reality. Finally, turning to automotive. Q2 revenue was $209 million, up 30% from a year ago
and up 26% sequentially. This reflects growing adoption of next-generation AI cockpit solutionsand autonomous vehicle development projects, including one particularly sizable development
services transaction that was recognized in the quarter.
In addition, in June, we announced a new partnership with the Volvo Group to develop AI
autonomous trucks, utilizing NVIDIA's end to end AI platform for training, simulation and in vehicle
computing. The strategic partnership will enable Volvo Group to develop a wide range of
autonomous driving solutions for freight transport, recycling collection, public transport,
construction, mining, forestry and more. This collaboration is a great validation of our long-held
position that every vehicle not just cars, but also trucks, shuttles, buses taxis and many others will
have autonomous capability one day.
Autonomous features can bring enormous value to the trucking industry in particular, as the
demand of online shopping put ever greater stress on the world's transport systems.
Expectations for overnight or same day deliveries create challenges that can only be met by
autonomous trucks, which can operate 24 hours a day. To help address these needs, NVIDIA has
created an end-to-end platform for autonomous vehicles.From AI computing infrastructure to
large scale simulation to in car computing. Multiple customers from OEMs like Mercedes-Benz,
Toyota and Volvo to Tier 1s like Bosch, Continental and ZF are already onboard. We see this is a
$30 billion addressable market by 2025.
Moving to the rest of the P&L. Q2, GAAP gross margins was 59.8% and non-GAAP was 60.1%, up
sequentially reflecting higher automotive development services, a favorable mix in gaming and
lower component costs. GAAP operating expenses was $970 million and non-GAAP operating
expenses were $749 million, up 19% and 8% year-on-year respectively. We remain on track for
high single-digit OpEx growth in fiscal 2020 while continuing to invest in the key platforms driving
our long-term growth mainly graphics, AI, and software and cars. GAAP EPS was $0.90, down 49%
from a year earlier. Non-GAAP EPS was $1.24, down 36% from a year ago.
With that, let me turn to the outlook for the third quarter of fiscal 2020. We expect revenue to be
$2.9 billion plus or minus 2%. GAAP and non-GAAP gross margins are expected to be 62% and
62.5% respectively, plus or minus 50 basis points. GAAP and non-GAAP operating expenses are
expected to be approximately $980 million and $765 million respectively. GAAP and non-GAAP
OI&E are both expected to be income of approximately $25 million. GAAP and non-GAAP tax
rates are both expected to be 10% plus or minus 1% excluding discrete items. Capital
expenditures are expected to be approximately $100 million to $120 million.
Further financial details are included in the CFO commentary and other information available on
our IR website. In closing, let me highlight upcoming events for the financial community. We will be
at the Jefferies Conference Hardware & Communications Infrastructure Summit on August 27th
and at the Citi Global Technology Conference on September 25th. With that, we will now open
the call for questions. Operator, would you please poll for the questions.
`Simona Jankowski, Investor Relations `
Operator, can you poll for questions, please.
Questions And Answers
Operator
(Operator Instructions) And your first question comes from the line of `C.J. Muse, Analyst, Evercore ISI with Evercore.
Q - `C.J. Muse, Analyst, Evercore ISIHi. Good afternoon. Thank you for taking the question, I guess, first question on gaming. How
should we think about your outlook into the October quarter vis-a-vis kind of normal seasonality?
How are you thinking about switch within that? And considering now that you have full Turing line
up as well as content truly coming to the forefront here, how do you think about trends beyond
the October quarter? Thank you.
A - `Jensen Huang, President and Chief Executive Officer `
Sure. Colette, why don't you take the switch question and then I'll take the rest of the RTX
question?
A - `Colette Kress, Executive Vice President and Chief Financial Officer `
Sure. From a gaming perspective, the overall switch or the overall console business definitely is a
seasonal business, we usually expect to see production ramping in Q2 and in Q3 with it coming
down likely in Q4. So you should see switch to be a portion definitely of our gaming business in
Q3.
A - `Jensen Huang, President and Chief Executive Officer `
Yeah, C.J. Thanks for the question. RTX is -- as you know is what -- first of all, RTX is doing great. I
think, we've put all the pieces in place to bring ray tracing into the future of games. The number
of games that blockbuster games have adopted RTX is really snowballing. We announced several
-- six games in the last couple of months, there's going to be some exciting announcements next
week at Gamescom. It's pretty clear now the future of gaming will include ray tracing.
The number of software developers that create with creative tools that adopted RTX is really
quite spectacular. We now have 40 -- over 40 ISV tools, that was announced at SIGGRAPH that
have accelerated ray tracing and video editing and some of the applications, amazing AI
capabilities for image optimization and enhancement support RTX. And so looking forward, this is
what I expect. I expect that ray tracing is going to drive a re-invigoration of gaming graphics. I
expect that the -- over 100 laptops that we have RTX design -- RTX GPUs designed into is going
to contribute to our growth.
Notebook gaming is one of the fastest growing segments of the gaming platform world. The
number of notebooks that are able to game is only a few percent, so it's extremely
underexposed and yet, we know that gamers are -- like the rest of us, they like thinner light
notebooks and -- but they like it to be able to run powerful games. And so this is an area that has
grown significantly for us year-over-year and we're expecting it to grow through the end of --
through the second half and through next year. And one of the things that's really exciting is our
RTX Studio line that we introduced recently. We observed and through our discussions with the
PC industry that the creatives are really underexposed and underserved by the latest
technologies and they want notebooks and they want PCs that have powerful graphics and they
use it for 3D content creation and high-definition video editing and image optimization and things
like that and we introduced a brand new line of computers that we call RTX Studio. Now the
OEMs were so excited about it and at SIGGRAPH, we now have 27 different laptops shipping and
more coming, and so I think RTX is really geared for growth.
We have great games coming, we got the SUPER line of GPUs. We have -- all of our notebooks
that were designed into that we're ramping and of course the new RTX Studio line. And so I
expect this to be a growth market for us.
Q - `C.J. Muse, Analyst, Evercore ISIVery helpful. If I could follow up on the data center side, perhaps you could speak directly just to
the Hyperscale side both internal and cloud and whether, you're seeing any green shoots, any
signs of life there and how you're thinking about what that rate of recovery could look like over
time?
A - `Jensen Huang, President and Chief Executive Officer `
With exception of a couple of hyperscalers, C.J., I would -- we are seeing broad-based growth in
data centers. In the area of training, the thing that's really exciting everybody and everybody is
racing towards is training these large gigantic natural language understanding models, language
models.
The Transformer model that was introduced by Google called BERT has since been enhanced
into XLNet and RoBERTa and, gosh, so many different -- GPT-2 and Microsoft's MASS and there
are so many different versions of these language models. And in AI, NLU, natural language
understanding, is one of the most important areas that everybody is racing to go do, and so
these models are really, really large, it's over a 1,000 times larger than image models that we
were training just a few years ago and they're just gigantic models.
It's one of the reasons why we built the DGX SuperPOD so that we could train these gigantic
models in a reasonable amount of time. The second area -- so that's training in the hyperscalers.
Now, the second area, where we're seeing enormous amounts of activity has to do with trying to
put these conversational AI models into services so that they could be interactive and in real time,
whereas photo tagging and photo enhancement is something that you could put offline and you
could do that while you have excess capacity when it's off the most busy time of the day, you
can't do that with language and conversational AI, you got to respond to the person in real time.
And so the performance that's required is significant, but more importantly, the number of
models necessary for conversational AI from speech recognition, to language understanding, to
recommendation systems, to text to speech, to wave synthesis, these five, six, seven models
have to be processed in real time -- in series and in real time, so that you can have a reasonable
conversation with the AI agent and so these type of activities is really driving interest and activity
at all of the hyperscalers.
My expectation is that this is going to continue to be a big growth opportunity for us. But more
importantly, in addition to that, we're seeing that AI is -- the wave of AI is going from the cloud to
the enterprise to the edge and all the way out to the autonomous systems. The place where
we're seeing a lot of excitement and we talked about that in the past and we're seeing growth
there has to do with the vertical industry enterprises that are starting to adopt AI to create new
products, whether it's a delivery robot or some kind of a chatbot or the ability to detect fraud in
financial services.
These applications in vertical industries are really spreading all over the place, there is some over
4,000 AI start-ups around the world, and the way that we engage them as we -- they use our
platform to start developing AI in the cloud, and as you know, we're the only AI platform that's
available on-prem and in every single cloud and so they could use our AI platforms for -- in all the
clouds, which is driving our cloud computing, external cloud computing growth. And then they can
also use it on-prem if their usage really grows significantly, and that's one of the reasons why our
Tesla for OEMs and DGX is growing.
And so we're seeing broad-based excitement around AI as they use it for their products and new
services and these 4,000, 4,500 startups around the world is really driving consumption of that.Operator
And your next question comes from the line of `Vivek Arya, Analyst, Bank of America Merrill Lynch. with Bank of America Merrill Lynch.
Q - `Vivek Arya, Analyst, Bank of America Merrill Lynch. `
Thanks for taking my questions. I actually had two as well. One quick one for Colette and one for
Jensen. Colette, good to see the gross margin recovery getting into October. Is this 62% to 63%
range a more sustainable level and perhaps a level you could grow off of as sales get to more
normalized levels? And then my bigger question is for Jensen, again on the data center side.
Jensen, when I look back between 2015 to 2018, your data center business essentially grew 10x
and then the last year has been a tough one with the slowdown in cloud CapEx and so forth.
When do you think your data center starts to grow back on a year-to-year -- on an year-on-year
basis, can that happen sometime in -- later this year?
And then just longer term, what is the right way to think about this business? Does it go back to
prior levels? Does it go at a different pace? This is the one part of the business that I think is
toughest for us to model. So any color would be very helpful.
A - `Colette Kress, Executive Vice President and Chief Financial Officer `
Great. So let me start first with your question. Vivek, regarding gross margins. Yes , thanks for
recognizing that we are moving towards our expectations that over time, we'll continue to see
our overall growth [ph] volumes improve. Essentially our businesses is normalized. We've reached
normalized levels through the last couple of quarters and this quarter, just very similar to what we
will see going forward as mix is the largest driver of what drives our overall gross margins and our
gross margin improvement.
A - `Jensen Huang, President and Chief Executive Officer `
Yeah, Vivek, if you look at the last -- last several years. There is no question our data center
business has grown a lot and my expectation is that it's going to grow a lot more. And let me
explain to you, why. Aside from a couple -- I got few -- a few uncontrollable circumstances and of
the exception of couple of large customers , the overall trend, the broad based trend of our data
center business is upwards, to the right, and it's growing very nicely. There is a couple of different
dynamics that's causing that on first principles to grow and of course one of them is as AI is well
known now to require accelerated computing.
Our computing architecture is really ideal for it. AI is not just one network, it's thousands of
different types of networks and these networks are getting more and more complex over time,
the amount of data you have to process is enormous. And so like all software programs, you
can't predict exactly how the software is going to get programed and having a programmable
architecture like CUDA, and yet optimized for AI like Tensor Cores that we created is really the
ideal architecture. We know also that AI is the most powerful technology force of our time, the
ability for machines to learn and write software by itself and write software that no humans can
write is pretty extraordinary and the applications of AI as you guys are watching yourself are just
spreading in every single industry.
And so the way, the way we think about AI is in waves, if you will, the first wave of AI is developing
the computer architecture and that was the first part where -- that's when a lot of people
discovered who we are and we emerged into the world of -- into the world of high performance
computing in AI. The second wave is applying the AI for cloud service providers or hyperscalers,
they have a large amount of data, they have a lot of consumer applications, many of them arenot life critical. And so therefore the application of an early technology, early adoption technology
was really viable. And so you saw -- you saw hyperscalers adopt AI and the thing that's really
exciting for us is beyond recommendations, beyond image enhancement, the area where we
believe the most important application for AI is likely conversational AI. Most people talking and
asking questions and talking to their mobile devices and looking for something or asking for
directions, instead of having a page of, a list of options, it responds with an answer that is very
likely a good one.
The next phase of AI is what we call vertical industry enterprise AI. And this is where companies
are using it, not just to accelerate, the business process internally, but they're using AI to create
new products and services. They could be new medical instruments to IoT based medical
instruments to monitor your health, it could be something related to an application that you use
for financial services for forecasting or for fraud detection, it could be some kind of device that
delivers pizza to you, delivery bots. And the combination of IoT and artificial intelligence, for the
very first time, you actually have the software capabilities to make use of all of the sensors that
you're putting all over the world and that's the next phase of growth.
And it effects companies from large industrials, transportation companies, retailers, you name it,
healthcare companies, you name it. And so that phase of growth of AI is the phase that we're
about to enter into. And then the longer term is an industry that we all know to be extremely
large but it takes time because it's life critical and it has to do with transportation, is a $100 trillion
industry. We know it's going to be automated, we know that everything that moves in the future
will be autonomous or have autonomous capabilities and that's just a matter of time before we
realize its full potential.
And so, so the net of it all is that, that I believe that AI is the single most powerful technology
force of our time and that's why we're all in on it and we know that acceleration in accelerated
computing is the perfect model for that and it started in the cloud, but it's going to keep moving
out into the edge and through data centers and enterprises and hopefully eventually, all the way
out into autonomous devices and machines in the real world. And so this is a big market and I am
super enthusiastic about it.
Q - `Vivek Arya, Analyst, Bank of America Merrill Lynch. `
Thanks.
Operator
And your next question comes from the line of `Toshiya Hari, Analyst, Goldman Sachs with Goldman Sachs.
Q - `Toshiya Hari, Analyst, Goldman Sachs `
Hi guys. Thanks very much for taking the questions. I had two as well. One for Jensen and the
other for Colette. Jensen, you guys called out inference as a significant contributor to growth in
data center last quarter. I think, you guys talked about it being a double-digit percentage
contributor. Curious, what you saw from inference in the quarter and more importantly, if you can
talk about the outlook both near term and long term. As it relates to inference that will be helpful.
And then secondly for Colette. I just wanted to double-click on the gross margin question. The
sequential improvement that you're guiding to is a pretty significant number. So I was just hoping,
if you can kind of break it down for us in terms of overall volume growth, mixed dynamics both
between segments and within segments and also to the extent DRAM pricing is impacting that,
any color on that would be helpful as well. Thank you.A - `Jensen Huang, President and Chief Executive Officer `
Yeah Toshiya, I got to tell you, I am less good at normal -- near term predictions than I am good
at thinking about long-term dynamics. But let me talk to you about inference. Our inference
business is -- remains robust. It's, it's double digits, it's a large part of our business. And, but
more importantly, the two dynamics that I think are near-term and that's going to drive growth.
Number one is interactive conversational AI. Interactive conversational AI inference.
If you simply ask the Chatbot a simple question. Where is the closest pizza and you would -- pizza
shop and you would like to have a conversation with this bot, it would have to do speech --
natural, it would have to do speech recognition as to understand what is it that you asked about,
it has to look it up in a recommender based on the locations you're at, maybe your preferences
of styles of pizza and the price ranges that you're interested in and how far you're willing to go,
to get -- to go get it.
It has to recommend a pizza shop for you to go to. It has to then translate that from text to
speech and then into human -- a human to understand a voice. And those models, those models
has to happen in just a few, ideally few hundred milliseconds. Currently, it's not that and it makes
it really hard for the services to be deployed quite broadly and used for all kinds of different
applications. And so, that's the near-term opportunity is interactive, conversational AI inference
and you could just imagine every single hyperscaler racing to go make those possible because
recently, we had some important breakthroughs in machine learning language models, the BERT
model that I mentioned earlier, so really, really an important development and this caused a large
number of derivatives that has improved upon it. And so near term conversational AI inference.
We're also seeing near term the inference at the edge. There are many types of applications,
where because of the laws of physics reasons, the speed of light reasons or the economics
reasons or data sovereignty reasons. It's not possible to stream the data to the cloud and have
the inference done at the cloud. You have to do that at the edge. You need the latency to be low,
the amount of data that you are streaming is continuous, and so you don't want to be paying for
that line rate the whole time and maybe the data is of great confidentiality or privacy. And so
we're seeing a lot of excitement and a lot of development for edge AI, smart retail, smart
warehouses, smart factories, smart cities, smart airports, you just make a list of those kind of
things. Basically locations, where there is a lot of activity, where safety or cost or a large amount
of materials is passing through, you could just imagine the applications. All of those really want to
be edge computing systems and edge inference systems.
And so those are near term -- two near term drivers. And I think, I think, it's fair to say both of
them are quite large opportunities.
A - `Colette Kress, Executive Vice President and Chief Financial Officer `
So to answer your question regarding gross margin in a little bit more detail. Probably our largest
area that we expect improvement in terms of our mix is our mix return regarding our overall
gaming business. We expect to have a full quarter of our SUPER lineup within the next quarter,
including our RTX as well as our notebook becoming a bigger mix as well as it grows. These
drivers are one of the largest reasons where we see that growth in our gross margin. We always
think about our component cost, our overall cost of manufacturing. So this is always baked in that
over time. But we'll continue to see improvements on that as well.
OperatorQ - `Harlan Sur, Analyst, JPMorgan `
Good afternoon, and thanks for taking my question. Again, on your data center business. Many of
your peers on the compute and storage side are seeing spending recovery by cloud and
hyperscalers in the second half of this year after a similar weak first half of the year. You guys saw
some growth in Q2, driven primarily by enterprise, it seems like you have some broadening out
of the customer spending this quarter, inferencing continues to see strong momentum. Would
you guys expect that this translates into a double-digit percentage sequential growth in data
center in Q3 off of the low base in Q2?
A - `Jensen Huang, President and Chief Executive Officer `
Our Hyperscale data center with a few customers don't give us very, very much. We don't get
very much visibility from a handful of customers in Hyperscale. However, we're seeing broad
based growth and excitement in data centers and the way to think about data center, our data
center business consists of Hyperscale training, internal training Hyperscale inference, cloud
computing and that's Hyperscale and that cloud is public cloud. And then we have vertical industry
enterprise, what sometimes we call enterprise, vertical industry enterprise. It could be
transportation companies, retailers, telcos, vertical industry adoption of AI, either to accelerate
their business or to develop new products and services. And then the -- so when you look at, look
at our data center from that perspective in these pieces, although we don't see as much -- we
don't get as much visibility as we like in a couple of the large customers. The rest of the business,
the rest of the hyperscalers, we're seeing broad based growth.
And so we -- we're experiencing the enthusiasm and the energy that maybe the others are and
so we'll keep a -- we'll keep reporting -- updating you guys as we go. We'll see how it goes.
Operator
And your next question comes from the line of `Timothy Arcuri, Analyst, UBS with UBS.
Q - `Timothy Arcuri, Analyst, UBS `
Thanks a lot. I had two. I guess first for Jensen. Volta has been around now for about two years.
Do you see signs of demand maybe building up ahead of the new seven nanometer product,
whenever that comes out. I guess, I'm just wondering whether there is some element of this is
more around product cadence that gets resolved as you do roll out the new product. That's the
first question. And then I guess, the second question, Colette, is of the $300 million growth into
October. It sounds like switch is pretty flat, but I'm wondering, if you can give us maybe some
qualitative sense of where the growth is coming from, is it maybe like two third gaming and one
third data center, something like that. Thanks.
A - `Jensen Huang, President and Chief Executive Officer `
Well, Volta -- data center products can't churn that fast. We -- gamers could -- could churn
products quickly because they are bought and sold one at a time. But data centers -- data center
infrastructure really has to be planned properly and the build out takes time and we expect Volta
to be successful, all the way through -- all the way through next year.
And software is still continuing to be improved on it, we're still improving systems on it and in fact
just one year -- in just one year, we improved our AI performance on Volta by almost two times,
80%. And so, you could just imagine the amount of software that's built on top of Volta and all
the Tensor Cores and all the GPUs connected with NVLink and the large number of nodes thatare connected to build supercomputers. The software -- the software of building these systems,
larger scale -- large scale systems is really, really hard. And that's one of the reasons why you
hear people talk about chips, but they never, they never show up because building the software
is just an enormous undertaking.
The number of software engineers we have in the Company is in the thousands and we have the
benefit of having built on top of this architecture for over a decade and a half and so when we're
able to deploy into data centers as quickly as we do, I think, we kind of lose sight of how hard it is
to do that in the first place. The last time -- the last time a new processor entered into a data
center was an x86 Xeon. And you just don't bring processors into data centers that frequently or
that easily and so I think the way to think about Volta is that -- that it's surely in its prime and it's
going to keep continuing to do well, all the way through next year.
A - `Colette Kress, Executive Vice President and Chief Financial Officer `
In regard to our guidance on revenue and we do guide in terms of the total. You have seen in this
last quarter, we executed a sequential increase really focusing on moving toward normalization of
our gaming business and we're now approaching the second half of the year, getting ready for
the back-to-school and the holidays . So you should expect also our gaming business to continue
to grow to reach that full normalization by the end of Q3.
We do expect the rest of our platforms to likely also grow. We have a couple of different models
on how that will come out. But yes, we do expect our data center business to grow and then we'll
see on the rest of our businesses as well.
Operator
Your next question comes from the line of `Matt Ramsay, Analyst, Cowen with Cowen.
Q - `Matt Ramsay, Analyst, Cowen `
Thank you very much. Good afternoon. A couple of questions, I guess the first one is Jensen , if
you have any, I guess high level qualitative commentary on how the new Super upgrades of your
Turing platform has been received in the market and how you might think about them
progressing through the year and then I guess the second question is a bigger one, Intel's talked
quite openly about One API. The software stack at Xilinx is progressing with Versal ACAP. I mean
you guys get a lot of credit for the decade of work that you've done on CUDA but I wonder if you
might comment on if you've seen any movement in the competitive landscape on the software
side for the data center space .
Thank you.
A - `Jensen Huang, President and Chief Executive Officer `
Super is off to a great start. Goodness, Super is off to a super start. And if you look at -- if you do
channel checks all over even though we've got -- we've got a lot of products in the channel and
we -- last quarter was a transitional quarter for us actually and we didn't, we shipped Super later
in the quarter but because the entire ecosystem and all of our execution engines are so primed,
we were able to ship a fair number through the channel. And so, and yet if you do, spot checks all
around the world. They are sold out almost everywhere. And the pricing in the spot market is
drifting higher than MSRP -- that just tells you something about demand. And so that's, that's
really exciting as Super is off to a super start. For -- and at this point, it's a forgone conclusion that
we're going to buy a new graphics card and it's going to last through two years, three years ,fouryears to not have ray tracing is just crazy. In a ray tracing content, it just keeps coming out and and
between the performance of Super and the fact that it has ray tracing hardware, it's going to be
super well positioned for through all of next year. Your question about APIs and software
programmability. APIs is just one of the issues. The large issue about processors is how do you
program it? The reason why x86es and CPUs are so popular is because they solve the great
challenge of software developers, how to program a computer.
And how to program a computer and how to compile for that computer is of paramount concern
to computer science, and it's a area of tremendous research. Going from single CPU to multi-
core CPUs was a great challenge, going from multi-core CPUs to multi-node multi-core CPUs is
enormous challenge. And yet when we create a CUDA, we in our GPUs, we went from one CPU
core or one processor core to a few to now in the case of large-scale systems, millions of
processor cores and how do you program such as a computer across multi-GPU, multi-node.
It's a concept that not easy to grasp and so I don't really know how one programming approach
or a simple API is going to make seven different type of weird things work together, and I can't
make it fit in my head, but programming isn't as simple as a PowerPoint slide, I guess. And I think
it's just -- time will tell whether one programming approach could fit seven different type of
processors when no time in history has it ever happened.
Operator
Your next question comes from the line of `Joe Moore, Analyst, Morgan Stanley with Morgan Stanley.
Q - `Joe Moore, Analyst, Morgan Stanley `
Great, thank you. I'm wondering if you could talk about the strength in the automotive business, it
looks like the services piece of that is getting to be bigger, what's the outlook for that part of the
business? And can you give us a sense of the mix between services and components at this
point?
A - `Jensen Huang, President and Chief Executive Officer `
Sure. Thanks, Joe. Our approach to autonomous vehicles. It comes in basically two parts. The first
part is a full stack, which is building the architected processor, the system, the system software
and all of the driving applications on top, including the Deep Neural Nets. The second part of it,
we call that a full stack self driving car computer. The second part of drive includes a end-to-end
AV development system. For those who would like to use our processors, use our system
software but create their own applications, we created the system that allows that basically
shares with them our computing infrastructure that we've built for ourselves that allows them to
do end-to-end development from deep learning development to the application of AV to
simulating that application to doing regression testing of that application before they deploy into
car. And the two systems that we use there is called DGX for training and constellation for
simulation and what is called replay. And then the third part of our business model is
development -- development agreements and otherwise known as NRE. These three elements,
full stack computer, end-to-end development flow and NRE project development -- product
development consists of the overall drive misses. And so, although the cars will take several
years to go into production.
We're seeing a lot of interest in working with us to develop self driving cars using our
development systems and entering into development projects. And so we're -- the number of
autonomous vehicle projects is quite large around the world as you could imagine. And so my
sense is that we're going to continue to do well here. The additional part of autonomous vehiclesand where the capability has been derived and it's going to see a lot more near-term
opportunities has to do with things like delivery shuttles, self driving shuttles and maybe cargo
movers inside walled warehouses, those kind of autonomous machines require basically the
same technology, but it's sooner and easier to deploy. And so we're seeing a lot of excitement
around that area.
Operator
Your next question comes from the line of `Aaron Rakers, Analyst, Wells Fargo with Wells Fargo.
Q - `Aaron Rakers, Analyst, Wells Fargo `
Yeah, thanks for taking the questions. And congratulations on the improved performance. At your
Analyst Day back a couple of months ago you had highlighted the installed base opportunity for
RTX and I think at that point in time, you talked about 50% being Pascal-based 48% being pre-
Pascal, you also alluded to the fact that you were seeing a positive mix shift higher in terms of the
price points of this, of this RTX cycle, so I am curious of where do we stand on the current
product cycle, and what are you seeing currently as we go through this product cycle in the Turing
platforms?
A - `Jensen Huang, President and Chief Executive Officer `
If we launched -- we launched well, first of all, the answer is that RTX adoption is faster than
Pascals adoption. If you normalize to time zero of launch. The reason for that is because Pascal
launched top to bottom, on the same day. And as you guys know, we weren't able to do that for
Turing. But if we did that for Turing, if we did that for Turing, the adoption rate is actually faster
and it's to me it's rather sensible. And the reason for that is because Pascal was basically DX12
and Maxwell was DX12 and Turing is the world's first DXR, their first ray tracing GPU. Brand new
functionality, brand new API and a lot more performance. And so I think it's sensible that Turing's
adoption is going to be rapid. The second element of Turing is something that we've never
talked about before, and we're mentioning it more and more because it's such an exciting
growth market for us is notebooks.
The installed base of Pascal has very, very little notebook in it. And the reason for that is because,
in the past, we were never able to put a high-performance gaming GPU into a thin and light
notebook, until we invented Max-Q and in combination with our energy efficiency. We were able
to -- we're now able to put a 2080 into a laptop and it's still beautiful.
And so, so this is a, this is effectively a brand new growth market for us and with so few people,
so few gamers in the world that are able to game on a laptop. I think this is going to be a nice
growth market for us. And then, and then the new market that we introduced and launched this
last quarter, it's called RTX Studio. And this is an underserved segment of the market where
consumers, enthusiasts, they could be artists that are working in small firms. They need, powerful
computers to do their work, they need powerful computers to do rendering and high-definition
video editing and and yet it's underserved by workstations because workstations are really sold
on a B2B basis into large enterprises.
And so we aligned all of the OEMs and created in a whole new line of notebooks call RTX Studio
and the enthusiasm has been great. We've launched 27 different laptops and I'm looking forward
to seeing the results of that. This is a tens of millions of people who are creators, some of them
professional, some of them hobbyists and they use Adobe -- Adobe Suites, they use Autodesk
and their suites and some of them use SolidWorks and some of them use all kinds of renders likeBlender, and these are 3D artists and video artists and this is a -- digital content creation is the
modern way of creativity.
And so this is an underserved market that we're excited to go, serve with RTX Studio.
Operator
And your last question comes from the line of `Stacy Rasgon, Analyst, Bernstein Research with Bernstein Research.
Q - `Stacy Rasgon, Analyst, Bernstein Research `
Hi guys, thanks for taking my questions. I have two for Colette. My first question is on data center.
So I know you say that you have broad-based growth except for a few hyperscalers, but you only
grew at 3% sequentially, it's about $20 million that doesn't sound like broad-based growth to me
unless like did the hyperscalers get worse or they just still so much bigger than like the rest of it, I
guess just what's going on in data center, how do I wrap my head around like broad-based
growth with relatively minimal growth observed?
A - `Colette Kress, Executive Vice President and Chief Financial Officer `
So to answer your question here Stacy on what we refer to when we're discussing the broad-
based scope is the substantial expansion that we have on the types of customers and the
industries that we are now approaching. As you know, even a year ago, we had a very, very small
base in terms of industry based Piper, excuse me, industry based AI workloads that they were
using.
Over this last quarter, we're continuing to see strong growth as we rollout all different types of AI
solutions both across the US and worldwide to these overall customers. Our Hyperscale is again a
couple of them, not necessarily growing, some of them are flat and some of them are growing,
depending on whether or not that's for client instances or whether or not they're using it for
internal use. So we believe that our continued growth with the industries is important for us for
the long term to expand the use of AI and we're just really pleased with what we're seeing in that
growth this quarter.
Operator
I will now turn the call back over to Jensen for any closing remarks.
A - `Jensen Huang, President and Chief Executive Officer `
Thanks, everyone. We're happy with our results this quarter and our return to growth across our
platforms. Gaming is doing great. It's great to see NVIDIA RTX reinvigorating the industry.
GeForce has several growth drivers. Ray trace games continue to gain momentum. A large
number of gaming laptops are rolling out and our new Studio platform is reaching the large
underserved community of creators.
Outside of few hyperscalers, we're seeing broad based growth in data centers. AI is the most
powerful technology force of our time and a once in a lifetime opportunity. More and more
enterprises are using AI to create new products and services. While leveraging AI to drive ultra
efficiency and speed in their business. And with hyperscalers racing to harness recent
breakthroughs in conversational AI. We see growing engagements in training as well as
interactive conversational inference. RTX -- CUDA accelerated computing. AI, autonomous
vehicles. The work we're doing is important, impactful and incredibly fun, we're just grateful,
there is so much of it. We look forward to updating you on our progress next quarter.Operator
This concludes today's conference call. You may now disconnect.